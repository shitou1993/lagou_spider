# lagou_spider
## 拉勾网全自动爬虫(Ajax异步加载+代理池+数据过滤）
#### 本爬虫可以完美爬取拉勾网上的职位信息，亲测可爬取30000条数据，请注意抓取频率控制，勿太过频繁！
拉勾网的职位数据是通过异步加载呈现的，我们直接找到异步加载的链接直接进行爬取数据，无需一页页信息抓取，节省时间。
代理池API采用的是[jhao104提供的API](https://github.com/jhao104/proxy_pool"悬停显示") <br/>
程序功能如下：

     lagou_spider.py：爬虫的主体部分，包括类目的获取，headers信息的预处理与拼接，以及发送请求，处理数据，
                     以及将数据写入数据库    
     
     page_num.py:    单独的一个爬虫，从每个类目的页面上爬取该类目下职位的总页数，防止页数超范围报错
     
     proxy.py:       从代理池中获取和删除代理
     
     main.py:        程序入口<br/>
编写过程中遇到的最大问题是：`cookie过期失效`的问题，不过现已完美解决<br/>

     set_cookie.py:通过Selenium+PhantomJS组合模拟访问可以成功抓取完整的cookie信息，与在chrome中复制的相同，
                   读者可以将该程序导入到lagou_spider.py中，用于自动生成cookie，从而实现完全自动化的爬虫！
                   读者自己动手！
     
     get_cookie.py:获取cookie的失败作品，此处仅供参考！此文件返回的cookie不完整，只有一部分，使用该程序生成
                   的cookie，还是会被反爬！
  
    
